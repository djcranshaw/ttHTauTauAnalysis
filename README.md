# ttHTauTauAnalysis

## Installation

Setup CMSSW environment:

	cmsrel CMSSW_9_4_7
	cd CMSSW_9_4_7/src/
	cmsenv
	git cms-init

Electron Scale & Smearing + MVA ID:

	git cms-merge-topic cms-egamma:EgammaPostRecoTools_940
	git cms-merge-topic cms-egamma:Egamma80XMiniAODV2_946

Get Analyzer:

	git clone https://github.com/zctao/ttHTauTauAnalysis.git
	cd ttHTauTauAnalysis
	git checkout cmssw_9_4_x
	cd -

Add MVA package if necessary:

	git clone https://github.com/zctao/ttHTauTauMVA.git

Add MEM interface if necessary:

	git clone https://github.com/zctao/ttHTauTau_MEM_Interface.git

Add package for kinematic hadronic top fit:

	git clone https://github.com/zctao/HTT_kinfit.git HadTop/HTT_kinfit

LeptonID package:

	git clone https://github.com/zctao/ttH-LeptonID.git ttH/LeptonID
	
For lepton-tau cross trigger scale factor:

	git clone -b tauTriggers2017_MCv2_PreReMiniaod https://github.com/truggles/TauTriggerSFs2017 TriggerSF/TauTriggerSFs2017

Compile:

	scram b -j 32

Add the area containing the Electron MVA weights:

	cd $CMSSW_BASE/external
	cd slc6_amd64_gcc630/
	git clone https://github.com/lsoffi/RecoEgamma-PhotonIdentification.git data/RecoEgamma/PhotonIdentification/data
	cd data/RecoEgamma/PhotonIdentification/data
	git checkout CMSSW_9_4_0_pre3_TnP
	cd $CMSSW_BASE/external
	cd slc6_amd64_gcc630/
	git clone https://github.com/lsoffi/RecoEgamma-ElectronIdentification.git data/RecoEgamma/ElectronIdentification/data
	cd data/RecoEgamma/ElectronIdentification/data
	git checkout CMSSW_9_4_0_pre3_TnP
	cd $CMSSW_BASE/src

Get data files before running analyzer:

	cd ttHTauTauAnalysis/ttHtautauAnalyzer/data
	./fetchDataFiles.sh
	cd -

When running with CRAB one needs to add the following option to the crab config file: config.JobType.sendExternalFolder = True This is needed until the PR including this ID will be integrated in CMSSW/cms-data.
It'd also be necessary to remove old MVA weights in RecoEgamma/PhotonIdentification/data/ and RecoEgamma/ElectronIdentification/data/ to reduce crab sandbox tarball size (max 100 MB).

## Usage

Produce sync ntuples:

	./ttHtautauAnalyzer/test/produceSyncNtuples.sh

Submit CRAB jobs to produce event ntuples:
	   
	submitCrabJobsv2.py <datasetlist.csv> --sample_list <sample_list> --prefix <prefix>
	
	submitCrabJobsv2.py -h for help

Collect and hadd CRAB outputs on EOS:

	haddCrabOutputs.sh <analysis_type> <samplelist> <eostopdir> <version> <prefix> <ntuplelist> <output_name> <list of samples to be added>

It would also generate something like 'ntuplelist.log' file to store the location of the output ntuples. Examples of using haddCrabOutputs.sh script are in ttHtautauAnalyzer/test/: haddCrabOutput2017reMiniAODv2.sh

Make flat mvaNtuple from event ntuple: UPDATE ME

	 produceMVANtuples.py <analysis_type> <list of sample names> -l <ntuplelist>

	 produceMVANtuples.py -h for help

This python script is a wrapper of binary 'makeMVANtuple' that does the actual production of mva ntuples. The python script picks the right ntuple file name based on the ntuplelist generated by hadd scripts. It also generates a list 'mvaNtuples.txt' of mva ntuples it produced.

Make data cards using flat mvaNtuples: UPDATE ME

	 makeDatacards.py <analysis_type> <list of channels included in datacards> <number of bins> -n <mvaNtupleList> -b <binningMap>

	 makeDatacards.py -h for help